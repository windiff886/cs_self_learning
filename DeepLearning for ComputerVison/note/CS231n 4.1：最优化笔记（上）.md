## 简介

在上一节中，我们介绍了图像分类任务中的两个关键部分：

1. 基于参数的**评分函数。**该函数将原始图像像素映射为分类评分值（例如：一个线性函数）。
2. **损失函数**。该函数能够根据分类评分和训练集图像数据实际分类的一致性，衡量某个具体参数集的质量好坏。损失函数有多种版本和不同的实现方式（例如：Softmax或SVM）。

上节中，线性函数的形式是![f\(x_i, W\)=Wx_i][11]，而SVM实现的公式是：  

![L][12]  

对于图像数据![x_i][13]，如果基于参数集![W][14]做出的分类预测与真实情况比较一致，那么计算出来的损失值![L][15]就很低。现在介绍第三个，也是最后一个关键部分：**最优化Optimization**。最优化是寻找能使得损失函数值最小化的参数![W][14]的过程。

**铺垫**：一旦理解了这三个部分是如何相互运作的，我们将会回到第一个部分（基于参数的函数映射），然后将其拓展为一个远比线性函数复杂的函数：首先是神经网络，然后是卷积神经网络。而损失函数和最优化过程这两个部分将会保持相对稳定。

## 损失函数可视化

本课中讨论的损失函数一般都是定义在高维度的空间中（比如，在CIFAR-10中一个线性分类器的权重矩阵大小是[10x3073]，就有30730个参数），这样要将其可视化就很困难。然而办法还是有的，在1个维度或者2个维度的方向上对高维空间进行切片，就能得到一些直观感受。例如，随机生成一个权重矩阵![W][14]，该矩阵就与高维空间中的一个点对应。然后沿着某个维度方向前进的同时记录损失函数值的变化。换句话说，就是生成一个随机的方向![W_1][16]并且沿着此方向计算损失值，计算方法是根据不同的![a][17]值来计算![L\(W+aW_1\)][18]。这个过程将生成一个图表，其x轴是![a][17]值，y轴是损失函数值。同样的方法还可以用在两个维度上，通过改变![a,b][19]来计算损失值![L\(W+aW_1+bW_2\)][20]，从而给出二维的图像。在图像中，![a,b][19]可以分别用x和y轴表示，而损失函数的值可以用颜色变化表示：

  

————————————————————————————————————————

![][21]一个无正则化的多类SVM的损失函数的图示。左边和中间只有一个样本数据，右边是CIFAR-10中的100个数据。**左**：a值变化在某个维度方向上对应的的损失值变化。**中和右**：两个维度方向上的损失值切片图，蓝色部分是低损失值区域，红色部分是高损失值区域。注意损失函数的分段线性结构。多个样本的损失值是总体的平均值，所以右边的碗状结构是很多的分段线性结构的平均（比如中间这个就是其中之一）。

  

—————————————————————————————————————————

我们可以通过数学公式来解释损失函数的分段线性结构。对于一个单独的数据，有损失函数的计算公式如下：  

![Li][22]  

通过公式可见，每个样本的数据损失值是以![W][14]为参数的线性函数的总和（零阈值来源于![max\(0,-\)][23]函数）。![W][14]的每一行（即![w_j][24]），有时候它前面是一个正号（比如当它对应错误分类的时候），有时候它前面是一个负号（比如当它是是正确分类的时候）。为进一步阐明，假设有一个简单的数据集，其中包含有3个只有1个维度的点，数据集数据点有3个类别。那么完整的无正则化SVM的损失值计算如下：


![L_0=max\(0,w^T_1x_0-w^T_0x_0+1\)+max\(0,w^T_2x_0-w^T_0x_0+1\)][25]  
![L_1=max\(0,w^T_0x_1-w^T_1x_1+1\)+max\(0,w^T_2x_1-w^T_1x_1+1\)][26]  
![L_2=max\(0,w^T_0x_2-w^T_2x_2+1\)+max\(0,w^T_1x_2-w^T_2x_2+1\)][27]  
![L=\(L_0+L_1+L_2\)/3][28]  

因为这些例子都是一维的，所以数据![x_i][13]和权重![w_j][24]都是数字。观察![w_0][29]，可以看到上面的式子中一些项是![w_0][29]的线性函数，且每一项都会与0比较，取两者的最大值。可作图如下：——————————————————————————————————————

  

![][30]从一个维度方向上对数据损失值的展示。x轴方向就是一个权重，y轴就是损失值。数据损失是多个部分组合而成。其中每个部分要么是某个权重的独立部分，要么是该权重的线性函数与0阈值的比较。完整的SVM数据损失就是这个形状的30730维版本。  

——————————————————————————————————————

需要多说一句的是，你可能根据SVM的损失函数的碗状外观猜出它是一个[凸函数__][31]。关于如何高效地最小化凸函数的论文有很多，你也可以学习斯坦福大学关于（[凸函数最优化__][32]）的课程。但是一旦我们将![f][33]函数扩展到神经网络，目标函数就就不再是凸函数了，图像也不会像上面那样是个碗状，而是凹凸不平的复杂地形形状。  

_不可导的损失函数。_作为一个技术笔记，你要注意到：由于max操作，损失函数中存在一些_不可导点（kinks），_这些点使得损失函数不可微，因为在这些不可导点，梯度是没有定义的。但是[次梯度（subgradient）__][34]依然存在且常常被使用。在本课中，我们将交换使用_次梯度_和_梯度_两个术语。  

## 最优化 Optimization

重申一下：损失函数可以量化某个具体权重集**W**的质量。而最优化的目标就是找到能够最小化损失函数值的**W** 。我们现在就朝着这个目标前进，实现一个能够最优化损失函数的方法。对于有一些经验的同学，这节课看起来有点奇怪，因为使用的例子（SVM 损失函数）是一个凸函数问题。但是要记得，最终的目标是不仅仅对凸函数做最优化，而是能够最优化一个神经网络，而对于神经网络是不能简单的使用凸函数的最优化技巧的。  

**策略#1：一个差劲的初始方案：随机搜索**

既然确认参数集**W**的好坏蛮简单的，那第一个想到的（差劲）方法，就是可以随机尝试很多不同的权重，然后看其中哪个最好。过程如下：  


​    
```py
    # 假设X_train的每一列都是一个数据样本（比如3073 x 50000）
    # 假设Y_train是数据样本的类别标签（比如一个长50000的一维数组）
    # 假设函数L对损失函数进行评价
    
    bestloss = float("inf") # Python assigns the highest possible float value
    for num in xrange(1000):
      W = np.random.randn(10, 3073) * 0.0001 # generate random parameters
      loss = L(X_train, Y_train, W) # get the loss over the entire training set
      if loss &lt; bestloss: # keep track of the best solution
        bestloss = loss
        bestW = W
      print 'in attempt %d the loss was %f, best %f' % (num, loss, bestloss)
    
    # 输出:
    # in attempt 0 the loss was 9.401632, best 9.401632
    # in attempt 1 the loss was 8.959668, best 8.959668
    # in attempt 2 the loss was 9.044034, best 8.959668
    # in attempt 3 the loss was 9.278948, best 8.959668
    # in attempt 4 the loss was 8.857370, best 8.857370
    # in attempt 5 the loss was 8.943151, best 8.857370
    # in attempt 6 the loss was 8.605604, best 8.605604
    # ... (trunctated: continues for 1000 lines)
    

在上面的代码中，我们尝试了若干随机生成的权重矩阵**W**，其中某些的损失值较小，而另一些的损失值大些。我们可以把这次随机搜索中找到的最好的权重**W**取出，然后去跑测试集：  

    
    
    # 假设X_test尺寸是[3073 x 10000], Y_test尺寸是[10000 x 1]
    scores = Wbest.dot(Xte_cols) # 10 x 10000, the class scores for all test examples
    # 找到在每列中评分值最大的索引（即预测的分类）
    Yte_predict = np.argmax(scores, axis = 0)
    # 以及计算准确率
    np.mean(Yte_predict == Yte)
    # 返回 0.1555

```

验证集上表现最好的权重**W**跑测试集的准确率是**15.5%，**而完全随机猜的准确率是10%，如此看来，这个准确率对于这样一个不经过大脑的策略来说，还算不错嘛！  

**核心思路：迭代优化**。当然，我们肯定能做得更好些。核心思路是：虽然找到最优的权重**W**非常困难，甚至是不可能的（尤其当**W**中存的是整个神经网络的权重的时候），但如果问题转化为：对一个权重矩阵集**W**取优，使其损失值稍微减少。那么问题的难度就大大降低了。换句话说，我们的方法从一个随机的**W**开始，然后对其迭代取优，每次都让它的损失值变得更小一点。  

&gt; 我们的策略是从随机权重开始，然后迭代取优，从而获得更低的损失值。  

**蒙眼徒步者的比喻**：一个助于理解的比喻是把你自己想象成一个蒙着眼睛的徒步者，正走在山地地形上，目标是要慢慢走到山底。在CIFAR-10的例子中，这山是30730维的（因为**W**是3073x10）。我们在山上踩的每一点都对应一个的损失值，该损失值可以看做该点的海拔高度。  

**策略#2：随机本地搜索**

第一个策略可以看做是每走一步都尝试几个随机方向，如果某个方向是向山下的，就向该方向走一步。这次我们从一个随机![W][14]开始，然后生成一个随机的扰动![delta W][35] ，只有当![W+delta W][36]的损失值变低，我们才会更新。

![](./assets/4_1.jpg)
>加入扰动后的梯度计算如图所示
这个过程的具体代码如下：  

  


​    
```py
    W = np.random.randn(10, 3073) * 0.001 # 生成随机初始W
    bestloss = float("inf")
    for i in xrange(1000):
      step_size = 0.0001
      Wtry = W + np.random.randn(10, 3073) * step_size
      loss = L(Xtr_cols, Ytr, Wtry)
      if loss &lt; bestloss:
        W = Wtry
        bestloss = loss
      print 'iter %d loss is %f' % (i, bestloss)

```

使用同样的数据（1000），这个方法可以得到**21.4%**的分类准确率。这个比策略一好，但是依然过于浪费计算资源。  

**策略#3：跟随梯度**  

前两个策略中，我们是尝试在权重空间中找到一个方向，沿着该方向能降低损失函数的损失值。其实不需要随机寻找方向，因为可以直接计算出最好的方向，这就是从数学上计算出最陡峭的方向。这个方向就是损失函数的**梯度（gradient）**。在蒙眼徒步者的比喻中，这个方法就好比是感受我们脚下山体的倾斜程度，然后向着最陡峭的下降方向下山。

在一维函数中，斜率是函数在某一点的瞬时变化率。梯度是函数的斜率的一般化表达，它不是一个值，而是一个向量。在输入空间中，梯度是各个维度的斜率组成的向量（或者称为导数**derivatives**）。对一维函数的求导公式如下：

![displaystylefrac{df\(x\)}{dx}=lim_{hto 0}frac{f\(x+h\)-f\(x\)}{h}][37]  

当函数有多个参数的时候，我们称导数为偏导数。而梯度就是在每个维度上偏导数所形成的向量。

  

**最优化笔记（上）完。**

  


## 译者反馈

1. **转载须全文转载并注明原文链接，否则保留维权权利**；  

2. 请知友们通过评论和私信等方式批评指正，贡献者均会补充提及。

「小钱钱将用于感谢校对和修改贡献者」


[1]: https://pic4.zhimg.com/4a97d93d652f45ededf2ebab9a13f22b_m.jpeg
[2]: https://zhuanlan.zhihu.com/intelligentunit
[3]: https://zhuanlan.zhihu.com/write
[4]: https://pic4.zhimg.com/d43a9c7ffaef1eef1d3f0b434e38dd3b_r.jpg
[5]: https://pic2.zhimg.com/5ab5b93bd_xs.jpg
[6]: https://www.zhihu.com/people/du-ke
[7]: http://link.zhihu.com/?target=http%3A//cs231n.github.io/optimization-1/
[8]: http://link.zhihu.com/?target=http%3A//cs.stanford.edu/people/karpathy/
[9]: https://www.zhihu.com/people/kun-kun-97-81
[10]: https://www.zhihu.com/people/li-yi-ying-73
[11]: http://zhihu.com/equation?tex=f%28x_i%2C+W%29%3DWx_i
[12]: http://zhihu.com/equation?tex=L%3D%5Cdisplaystyle%5Cfrac%7B1%7D%7BN%7D%5Csum_i%5Csum_%7Bj%5Cnot%3D+y_i%7D%5Bmax%280%2Cf%28x_i%3BW%29_j-f%28x_i%3BW%29_%7By_i%7D%2B1%29%5D%2B%5Calpha+R%28W%29
[13]: http://zhihu.com/equation?tex=x_i
[14]: http://zhihu.com/equation?tex=W
[15]: http://zhihu.com/equation?tex=L
[16]: http://zhihu.com/equation?tex=W_1
[17]: http://zhihu.com/equation?tex=a
[18]: http://zhihu.com/equation?tex=L%28W%2BaW_1%29
[19]: http://zhihu.com/equation?tex=a%2Cb
[20]: http://zhihu.com/equation?tex=L%28W%2BaW_1%2BbW_2%29
[21]: https://pic2.zhimg.com/94dd0714f65ef94b3cbfff4780b1988d_b.png
[22]: http://zhihu.com/equation?tex=Li%3D%5Csum_%7Bj%5Cnot%3Dy_i%7D%5Bmax%280%2Cw%5ET_jx_i-w%5ET_%7By_i%7Dx_i%2B1%29%5D
[23]: http://zhihu.com/equation?tex=max%280%2C-%29
[24]: http://zhihu.com/equation?tex=w_j
[25]: http://zhihu.com/equation?tex=L_0%3Dmax%280%2Cw%5ET_1x_0-w%5ET_0x_0%2B1%29%2Bmax%280%2Cw%5ET_2x_0-w%5ET_0x_0%2B1%29
[26]: http://zhihu.com/equation?tex=L_1%3Dmax%280%2Cw%5ET_0x_1-w%5ET_1x_1%2B1%29%2Bmax%280%2Cw%5ET_2x_1-w%5ET_1x_1%2B1%29
[27]: http://zhihu.com/equation?tex=L_2%3Dmax%280%2Cw%5ET_0x_2-w%5ET_2x_2%2B1%29%2Bmax%280%2Cw%5ET_1x_2-w%5ET_2x_2%2B1%29
[28]: http://zhihu.com/equation?tex=L%3D%28L_0%2BL_1%2BL_2%29%2F3
[29]: http://zhihu.com/equation?tex=w_0
[30]: https://pic3.zhimg.com/3f6fbcd487b1c214e8fea1ea66eb413e_b.png
[31]: http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Convex_function
[32]: http://link.zhihu.com/?target=http%3A//stanford.edu/%7Eboyd/cvxbook/
[33]: http://zhihu.com/equation?tex=f
[34]: http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Subderivative
[35]: http://zhihu.com/equation?tex=%5Cdelta+W
[36]: http://zhihu.com/equation?tex=W%2B%5Cdelta+W
[37]: http://zhihu.com/equation?tex=%5Cdisplaystyle%5Cfrac%7Bdf%28x%29%7D%7Bdx%7D%3D%5Clim_%7Bh%5Cto+0%7D%5Cfrac%7Bf%28x%2Bh%29-f%28x%29%7D%7Bh%7D