# CNN的可视化与理解

在之前我们讨论了一系列内容

- 注意力机制：注意力如何成为我们可以添加到当前的神经网络中的机制，让模型在不同的时间步长上专注于输入的不同部分，然后构建通用自注意力层，用来构建新的神经网络模型
- Transformer：我们可以使用自注意力来构建这个新的神经网络模型，它完全依赖于对注意力的处理

但是我们在面对视觉任务的时候，我们如何判断神经网络学到了什么，假设我们训练了一个卷积神经网络模型，那么神经网络内部寻找的中间特征是什么，如果能够观察神经网络内部并了解不同的层在寻找什么特征

## 卷积层可视化

先从线性分类器开始思考，我们有这样的想法，即线性分类器正在学习一组模板，每个类都有一个模板，并且类分数是由我们的线性分类器计算的，是学习模板和输入图像的内积

当我们推广到卷积神经网络的时候，我们也有同样的想法

对于网络中第一层的卷积核，经过学习之后，当它继续围绕图像滑动之后，就可以获取一个内积（代表匹配度）

如果我们将这些卷积核可视化，那么就会发现，过滤器作为一个图像，可以对匹配的图像给出强烈响应，所以通过可视化卷积核的方法，我们可以对这些层所要寻找的特征有所了解

下面是四个不同模型，在ImageNet数据集上进行预训练之后，将第一层卷积核进行可视化

![EECS498_L14_6](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_6.png)

我们可以看到，尽管不同模型的架构不同，但是第一层卷积核想寻找的特征却是很接近

我们可以想一下卷积神经网络到底在卷积什么，CNN中的卷积是一种离散的矩阵乘法计算，可以理解为是连续卷积的离散化，而卷积神经网络的卷积，则是想每个卷积层都学习出一种合适的卷积核（卷积核是一个函数）

![PointCloudDL_ShenlanOpen_ConvNet-On-PointCloud_LiFuxin_16](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/PointCloudDL_ShenlanOpen_ConvNet-On-PointCloud_LiFuxin_16.png)

如果我们想将可视化方法应用在更高层上，会有一些问题，这是因为在第一层卷积层，卷积核通常会学习到一些基本的视觉特征，如边缘和颜色。例如，一个卷积核可能会在检测到垂直边缘时产生高的激活值。我们可以通过将这些卷积核的权值可视化为图像来查看这些特征。

但是在更深的卷积层，卷积核通常会学习到更复杂的特征。由于这些特征是在高维空间中学习的，因此可能难以直接可视化。然而，可以通过一些方法（例如，反卷积或特征反向投影）来尝试理解这些特征。

但是我们仍然可以在第二层上看到一些情况，那就是，他们仍然在寻找一种斑点图案或边缘，但现在不再寻找边缘或RGB特征空间中的斑点，而是寻找特征空间中由前一个卷积层产生的斑点或边缘

随着神经元层数的加大，所寻找的特征也越来越语义化，或者说神经元的语义信息越来越明显了（如下图所示），或者可以说神经元越来越有选择性了，我们可以这样理解：高层的神经元都是一个简易的物体检测器，可以检测特定的物体是否存在

![20](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/20.png)

![EECS498_L14_7](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_7.jpg)

但是我们仍然无法对这些卷积核在寻找什么这件事上有一种强烈的直觉，卷积核可视化这个方法也无法让我们理解更高层的卷积核在做什么，所以我们需要使用其他方法来尝试理解卷积神经网络的其他层在干什么

我们先尝试跳过前面的卷积层，然后直接尝试理解最后一个全连接层在干什么

## 全连接层可视化

AlexNet的FC7层有4096个特征，使用线性变换之后可以提供ImageNet数据集中一千个类的类分数，所以我们可以尝试做的一件事是理解这个4096维向量表示什么

这个训练好的AlexNet在干什么呢？它获取我们的输入图像并将其转换为4096维向量，然后在该 4096 维向量之上应用线性分类器，所以我们可以尝试通过了解4096 维向量内部发生的事情来可视化地理解

我们使用训练好的AlexNet模型，在测试集的图像上进行前向推理，然后记录每个图像所生成的4096维特征向量，一旦我们收集了这类图像数据集及其特征向量，我们就可以尝试使用各种技术将它们可视化，首先我们在这些特征向量上使用最近邻算法

![EECS498_L14_9](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_9.jpg)

回想我们第一次使用最近邻算法的时候，是直接使用像素进行计算的，这个时候最近邻算法倾向于包含相似像素的图像判定为一类，尽管同一个类别的图像并不是真的同一个类别

在这里，我们使用AlexNet计算的特征向量进行最近邻搜索，这可以让我们理解分类器是如何学习特征空间中图像彼此之间的接近程度的，或者说，分类器是如何根据图像的特征向量来判断哪些图像是一个类别的

我们看上图中的例子，以第二行的大象类别为例，尽管不同图像中的背景和大象有不小的区别，但是仍然可以很好地完成分类，或者说，AlexNet在对图像进行处理的时候，忽略了图像中很多低级像素内容

亦或者可以这样理解，在这个向量中以某种方式编码像大象这样的东西，然后得到这样一个很好的特征向量

## 数据驱动的可视化方法（Data-Driven）

这种方法类似于神经科学家研究大脑的方法，他们设计一些简单的刺激，将其投射到视网膜上，然后检查皮层里面神经元的响应，然后进行相关性分析

我们使用类似的方法，我们准备了一个20万张混合了物体和场景的图像数据集，然后分别在ImageNet和places数据集上训练网络，这两个网络都没有看过这二十万张图片，然后我们将这个数据集放入两个网络，并且记录每一层每个神经元的响应，并且进行和图片的相关性分析，然后就可以估计神经元所喜欢的模式及其感受野

![17](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/17.png)

## 降维方法可视化

我们可以在4096维特征空间中训练分类器，但是我们这些三维空间中的人类很难去理解这个高维空间，所以只能想办法进行降维，让维数降低到二维三维，才可以进行人类可理解的可视化显示

这里首先是主成分分析（principal component analysis，PCA）方法，这是一种线性降维方法，可以尽可能保留高维特征空间的结构，并且进行线性的降维投影

![EECS498_L14_10](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_10.jpg)

然后还有一种方法就是t-SNE算法（t-Distributed Stochastic Neighbor Embedding），这是一种用于数据可视化的降维技术，特别擅长处理高维数据。这种算法由Laurens van der Maaten和Geoffrey Hinton于2008年开发。t-SNE主要用于可视化高维数据集在二维或三维空间的分布，特性是非线性、保留局部结构和高维可视化

1. **非线性**：与主成分分析（PCA）等线性降维技术不同，t-SNE是一种非线性降维技术。这使得它能够处理复杂的数据模式。
2. **保留局部结构**：t-SNE尤其擅长保留数据的局部结构。这意味着在高维空间中相近的点在低维空间中也会相近。
3. **高维可视化**：由于t-SNE通常用于将数据降维到二维或三维，因此它是一种非常有用的数据可视化工具。

需要注意的是，尽管t-SNE有很多优点，但它也有一些限制。例如，t-SNE对超参数的选择很敏感，对于不同的超参数可能会得到非常不同的结果。此外，t-SNE的运算成本相当高，对于大规模数据集可能难以处理。

然后，我们对AlexNet在MNIST上计算的特征向量进行降维可视化，就可以看到，对于十种数字，的确倾向于不同的区域，这让我们知道，这个网络的确可以以某种方式对不同类进行编码

![9](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_10.jpg)

## 卷积激活的可视化

另外一种理解卷积神经网络想寻找什么东西的方法，就是将中间层的卷积激活可视化

比如说AlexNet的第五个卷积层，其输出特征图是13x13大小，128通道，这意味着第五个卷积层中有128个卷积核，所以我们可以尝试将单个通道的特征图转化为灰度图，当然，其中会有大量的纯黑色图像，因为激活函数的存在

对于特征图不为零的，我们与原始输入图像对齐，以下图为例，我们输入一张人像图，其中的一个卷积核实际上类似于人脸形状，这就是因为这个卷积核以某种方式与人脸或者人类肤色对齐了，所以让我们感觉，也许这个神经网络这一层内的卷积核以某种方式学会了对人脸或人类肤色做出反应

![EECS498_L14_12](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_12.jpg)

我们可以将这些卷积激活进行可视化，让我们有一些直觉，去感觉这些不同的卷积核可能会响应什么不同特征

为什么大多数图片都是黑色的，可能是因为ReLU是非线性的，任何负数都会被设置为零，任何正数都会原封不动，同时当我们可视化这个东西时，我们需要以某种方式将其压缩为0-255区间，可能对图像的整体亮度产生一些影响

## 最大激活区域（Maximally Activating Patches）

这个概念描述的是在给定神经网络层级中，能产生最大激活值的图像片段或区域；在训练卷积神经网络时，每一层的神经元都会学习到对某些特征的响应，例如颜色、形状或更复杂的图像特征。当输入图像中包含这些特征时，相应的神经元会被 "激活"。因此，"Maximally Activating Patches" 就是那些能引发特定神经元最强烈反应的图像区域，也叫**最大激活图块**。

通过观察这些最大激活区域，我们可以理解和解释神经网络是如何 "看" 图像的，以及它是如何做出决策的。这对于理解神经网络的工作原理，提高模型的性能，以及提高模型的可解释性都是非常有用的。

因为这是一个卷积神经网络，所以激活网格中的特征网格中的每个元素，实际上都对应于输入图像中的一些有限大小的图块（最小是一个卷积核大小，最大是整张图大小），这是因为假设卷积核都是3x3大小，两次卷积堆叠，一个元素就取决于5x5的一个图块，三次堆叠就是取决于7x7的图块

还是那个训练好的模型，我们这一次选择中间的卷积层，然后输入所有的图像，并且找到那些所选神经元作出最高响应的图块，然后记录并且显示这些图块，我们就可以尝试了解所选神经元正在寻找什么特征

![EECS498_L14_13](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_13.jpg)

从上图我们可以看到，第一行的元素，在尝试寻找狗鼻子样式的特征，或者看其他的元素，对应的最大激活区域都有很类似的特征

这种最大激活区域的可视化方法，可以让我们了解中间卷积层在识别什么

当然，这种方法也可以用来估计神经元的感受野

我们准备了一些图片，并且通过某些方法抹去图片中的一小块区域（比如说11x11大小的一个正方形），然后将修改的图片和原图都放入神经网络，并且记录神经元的响应，看哪些区域跟原图的响应有区别，就说明这些区域对某个神经元的响应有重要影响，这样就可以得到一个map，表示图片中哪些区域对神经元最重要（下图中上方左数第二个）每一个图都这样处理和记录，然后将其对齐，移动到图像中心，就可以得到一个神经元的感受野

![18](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/18.png)

我们对每一层每个神经元都这样处理和记录，就可以得到其感受野，比如说上图中下方的示意图，我们发现，越高层的神经元感受野越大，并且不同神经元的感受野会有不一样的形状，此外，神经元的实际感受野比理论上的感受野要小（黄色区域是理论感受野，橙色区域是实际估计出的感受野，大概实际感受野的大小是理论感受野的四分之一）

这种方法也有应用，可以利用神经元的响应去完成定位和分割

![19](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/19-1685801717785-4.png)

当然还有一些关于感受野的其他工作，比如说可以使用高斯分布去拟合感受野大小（上图），并且进行了理论证明

我们使用这种方法，去查看神经元更喜欢什么样的特征，下面是基于某个训练好的模型上，第五个pool层的某个神经元，其实这个神经元就在寻找海洋或者海岸的特征

![22](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/22.png)

当然这种方法，有时候也会被外观接近的不同类别的个体所影响，比如下图中，神经元在寻找台球桌（下图中上半部分）的过程中，就会被类似于台球桌的游泳池（下图中下半部分，红色框中）所干扰

![25](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/25.png)

## 类激活映射（Class Activation Mapping）

类激活映射（CAM）是一种用于可视化卷积神经网络中类别特定激活区域的方法。它能够帮助我们理解CNN在图像分类任务中对不同类别的判别性区域。

CAM的基本原理是在CNN最后一个卷积层之后添加全局平均池化层，然后通过权重的线性组合将特征图映射到类别得分，这样就将最后的预测层和最后一个卷积层直接联系起来了，最后一层卷积层得到的是检测器（也就是不同的神经元）检测的结果（如下图所示，每个类检测器都会对图像中相应类的对象，即下图中的热力图），如果乘以权重（代表了类别信息）并且进行线性叠加，就得到了一个**类激活图（Class Activation Map）**，表示对于某个类别，图片中哪些区域可以对分类有影响。通过反向传播，可以获得特征图中每个空间位置对于每个类别得分的重要性权重。

![44](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/44-1685845535305-9.png)

CAM可视化结果表示为热度图，将特定类别的重要激活区域以高亮显示（也有定位的用途）。这些激活区域通常与输入图像中属于该类别的判别性区域相关联。CAM的目的是提供一种直观的方式来理解CNN在图像分类中的决策依据，并可用于可视化模型的关注区域。类激活映射在计算机视觉领域被广泛应用于解释和分析卷积神经网络模型的分类能力。

![45](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/45-1685845922393-11.png)

对于不同的结果，都可以生成不同的类激活图，如上图所示，同时我们发现，使用全局平均池化层代替全连接层之后，预测精度只有极小幅度下降（2-3%），但是参数量大大减小，并且可以通过增加一两个卷积层的方式去提高网络的拟合能力，使得精度恢复

![46](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/46-1685846173069-13.png)

## 通过遮挡方式的显著性可视化

所以我们可以尝试做的另一件事，是了解这些网络使用输入图像中的哪些像素来计算结果，这个对分类问题很重要

![EECS498_L14_15](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_15.jpg)

我们还是有一个训练好的模型，然后我们输入一张大象图片，然后得到了正确的分类结果，我们想知道，其中哪些像素，对于网络将图片分类为大象这件事上，做出了更大贡献

我们对大象图片进行一些处理，使用灰色方块将某些地方遮挡住（或者将图像中某些区域的像素替换掉），然后将这个图像传入卷积神经网络，然后重复这个过程，每次覆盖不同区域，然后输入到网络中进行分类，计算网络中每个位置有大象的概率，然后我们就可以得到一个代表分布概率的**显著性图（saliency map）**（上图右侧），我们就可以看到哪些像素对于分类很重要

如果我们将大象所在位置遮挡，那么相应的显著性地图上大象的预测概率就会下降很多，这是很直观的，意味着神经网络实际上以某种方式在看图像的正确部分做出分类决定

我们在其他图片上重复这种方式，可以得到类似的结果：我们遮挡住天空或者山脉，那么神经网络仍可以准确预测（或者很自信的将其归类正确），但是如果我们将车或者帆船遮挡，那么就不会那么准确

但是，如果你的数据集里面，存在了可以让神经网络作弊的方式，使得神经网络看错但是仍然得到正确答案，那么我们通过这种方式就可以看出神经网络是否有问题，或者说判断神经网络是否在看那些我们认为它在做正确决定时候应该看的图像部分，比如说神经网络看到海上帆船的图片，它看到特定颜色的海水就判断图片为帆船，而不是看到帆船才判断图片为帆船

但是这种方式，要计算很多次，计算量大，所以我们在考虑其他的方式

## 反向传播方式的显著性可视化

首先获取我们的输入图像，即这只可爱的狗（下图所示），然后在反向传播中，我们可以计算狗得分相对于输入图像中每个像素的梯度，这告诉我们输入图像中的每个像素，如果我们稍微改变那个像素，那么它会在多大程度上影响网络末端的分类分数，在显著性图中，亮度较高的区域表示这些像素对模型的决策影响较大

![EECS498_L14_17](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_17.jpg)

利用这种图像梯度，我们可以得到一个**梯度显著性图（也叫梯度回传图）**，就上图右下角的有点类似于幽灵的图片，它告诉我们，最能改变分类分数的像素实际上是狗内部的像素，如果我们要更改狗外部的一些像素，那么分类分数可能不会改变那么多

所以这再次让我们知道，神经网络正在查看图像的正确部分，你可以使用它来获得一些关于神经网络正在学习什么的直观理解（如下图所示）

![EECS498_L14_18](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_18.jpg)

但是注意一下，我们使用这种方式必须有一个已经训练好的模型了，如果我们在一个还没有训练好的模型上这样操作，那么我们得到的显著性图可能会非常杂乱

这是因为卷积结构实际上对计算的函数有很强的正则化作用，也就是使得模型尽可能利用更多特征来进行判断，但是未训练的模型还没有学习到如何有效地从输入图像中提取有用的信息，模型对任何特定的输入图像或类别都没有偏好，所以我们无法从梯度显著性图中得到有意义的解释。

也就是说，图像中的任何区域都不会对模型的输出产生显著的影响，因为模型还没有学习到如何区分不同的类别或特征。

然而，随着模型的训练过程的进行，它将开始学习到如何从数据中提取有用的特征，这时我们就可以开始使用梯度显著性图来理解和解释模型的行为了。

## 显著性图：无监督分割

我们已经得到了梯度的显著图，我们是不是可以根据这个显著图，去无监督的分割出图像中的对象，比如说下图中，我们可以分割出蚱蜢、蛇等对象

![EECS498_L14_19](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_19.jpg)

我们可以尝试使用这些显著图，并在这些神经网络计算所得的显着图上使用某种图像处理技术，然后我们就可以使用训练好的网络，来以某种方式实现对输入图像中与对象类别对应的部分的分割操作

所以我们有这种想法，使用梯度信息计算每个像素，查看每个像素对最终输出分数的影响有多大，这样可以理解神经网络正在做什么，但是我们不局限于此，我们想使用梯度信息来查看网络内部寻找的中间特征

## 通过引导反向梯度寻找的中间特征

我们想使用梯度信息来查看网络内部寻找的中间特征，那么我们使用训练好的模型，然后对一张图片进行测试并且完成**中间层开始的反向传播**，然后就可以看到哪些像素不会影响分类结果，但是会影响中间层神经元的值，或者说查看哪些像素对中间神经元的影响最大

注意一下，我们使用训练好的模型和一个图像完成前向推理之后，不是从损失函数或者分类结果开始反向传播的，而是从中间层开始的

引导反向传播的基本思想是：在反向传播过程中，如果某个神经元的激活值是负的，那么就将这个神经元的梯度设为零。这意味着，只有那些既被激活又对特定类别有正影响的特征，才会被视为对该类别的预测重要。

对于使用 ReLU 激活函数的网络，这可以通过在反向传播过程中将所有负的梯度设为零来实现。这样做的直观理解是，我们只关心那些激活值为正（即被激活）并且对预测结果有正向贡献的神经元。

使用这种方法来可视化的时候，可以使图像变得更好，便于我们查看哪些像素对神经元的输出有更大影响，下图就展示了不同神经元在寻找哪些特征，或者说哪些像素的确对神经元的输出有重大影响

![EECS498_L14_22](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_22.jpg)

## 梯度上升（生成图像）

之前我们是针对训练好的模型来测试图像，看哪些像素会影响到神经元输出或者分类结果，我们现在可以更进一步，不是去测试图像，而且尝试去找到一个可以最大化神经元输出的图像

激活最大化是一种用于理解深度学习模型，特别是 CNN 的方法。它的基本思想是生成一张图像，这张图像能最大化某一特定神经元的激活值。通过这种方式，我们可以直观地理解这个神经元是如何响应输入的。

同时我们也要使用正则化函数，来使得我们的图像变得自然，避免过拟合和保持生成的图像的可解释性，否则生成的图像可能会出现过度复杂、难以解释，或者在人类看来并不像是任何有意义图像的情况。这是因为神经网络可能会过度地在每个像素上调整细节，以获取可能的最大激活，而这些细节可能对人眼是无法理解的。

![EECS498_L14_24](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_24.jpg)

具体来说，激活最大化首先选择一个神经元，然后创建一张随机噪声图像或者零元素图像。接着，它使用梯度上升方法来修改这张图像（这有些类似于训练网络模型，使损失函数最小），使得所选神经元的激活值最大化。这个过程持续多次迭代，直到图像收敛（如）。

![EECS498_L14_25](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_25.jpg)

通过这种方式，我们可以生成一张图像，这张图像能够“激活”模型中的一个特定神经元。这可以帮助我们理解这个神经元在寻找什么样的特征，从而提供一种理解模型如何工作的方法。例如，对于一个图像分类模型，我们可以使用激活最大化来理解模型是如何识别出不同类别的。

![EECS498_L14_28](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_28.jpg)

上面这张图就是使用已经训练好的模型，对神经元进行反向传播生成的一些最大化激活图像，可以看到一些有点粗糙的形状，因为所使用的正则化器不是特别好，所以图像并不是特别逼真，所以一直有人尝试发明更好的正则化器使得这种方式生成的图像更自然，比如说下图中的图像就更为自然

![EECS498_L14_30](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_30.jpg)

当然，有的人对于使用更复杂的自然图像正则化器来生成看起来更逼真的图像这件事非常着迷，所以就有了一些非常奇特的正则化器，它实际上基于一个生成对抗网络，可以生成一些非常精美自然的图像（如下图所示）

![EECS498_L14_35](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_35.jpg)

不过，所选的用于梯度上升的神经元越高层，生成的图像就更有语义，如下图所示

![33](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/33.png)

这种研究方向的初衷是为了理解神经网络实际上在寻找什么，讲师Justin博士认为，越执着于强大的正则化器来寻找这些最大激活图像，就越会误入歧途，所以当他看到这样精美的图像时，很难说其中有多少是卷积神经网络实际正在寻找的；他倾向于使用简单的正则化器，认为这样才可以更纯粹地了解卷积神经网络在寻找什么样的原始图像和特征

## 对抗性样本

对抗性攻击是一种针对神经网络的攻击方式，通过向输入数据中加入极小的扰动（对于人类几乎无法察觉的改变），可以导致神经网络产生错误的预测。

这种现象首次在2014年由Ian Goodfellow等人的研究中发现。他们发现，通过优化一个目标函数，可以生成特定的噪声，将这个噪声添加到原始图像上，即使这个噪声非常小到人眼几乎看不出来，但却能够导致神经网络完全改变其预测结果。这种被添加了噪声的图像被称为**对抗性样本（Adversarial Example）。**

下图中，分别对大象和帆船图像中加入人类无法察觉的噪声，会导致神经网络预测结果的严重偏差。

![EECS498_L14_37](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_37.jpg)

对抗性攻击揭示了深度学习模型在面对微小扰动时的脆弱性，这对于深度学习的安全性和鲁棒性研究具有重要意义。例如，在自动驾驶、医疗诊断等关键领域，对抗性攻击可能会导致严重的后果。

对于如何防御对抗性攻击，目前还没有十分完美的解决方案，但已有一些常用的防御策略，如对抗性训练（在训练过程中加入对抗性样本），或是输入转换（例如，对输入进行降噪或压缩，以去除可能的对抗性噪声）。

## 特征反转

特征反转（Feature Inversion）是一种在计算机视觉中常用的技术，旨在理解卷积神经网络的内部运行机制。其核心思想是，给定一个图像，得到神经网络中的特定层的特征表示，然后使用梯度下降法，试图重建一个在特征上与原始输入图像尽可能相近的图像。

![EECS498_L14_38](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_38.jpg)

特征反转的过程通常是通过优化算法（如梯度下降或梯度上升）实现的。首先，我们从CNN中选择一个特定层，然后将一张输入图像通过网络进行前向传播，得到该层的特征表示。接下来，我们创建一张随机噪声图像，并通过网络前向传播到相同的层，得到该噪声图像的特征表示。然后，我们定义一个损失函数，其值为这两个特征表示之间的差异，最后使用优化算法来最小化这个损失。在这个过程中，噪声图像会被不断调整，使得它在网络中的特征表示尽可能接近原始图像的特征表示。

这种技术可以帮助我们理解神经网络中的每一层在学习什么。例如，如果我们选择的是网络的第一层，那么通过特征反转生成的图像通常会与原始图像非常接近，因为第一层通常学习到的是低级特征，如边缘和颜色等。然而，如果我们选择的是网络中更深的层，那么生成的图像可能会更加模糊和抽象，因为这些层通常学习到的是更高级的、抽象的特征。

我们使用一个训练好的VGG网络，我们输入图像y（下图中最左侧），然后经过不同数量的层提取特征，然后使用特征反转方法开始合成图像

在最开始的时候，我们发现，生成的图像与输入图像非常接近，几乎一致，意味着基本上所有的图像信息都被浅层神经元捕获，当层数增多，我们再反转的时候，我们发现越来越多的低级信息（局部的纹理和颜色这些）开始丢失，但是保留了图像的整体结构或者形状

![EECS498_L14_39](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_39.jpg)

特征反转为我们提供了一种直观的方法，去理解神经网络中的每一层在图像识别过程中的作用，从而有助于我们更好地理解和改进神经网络模型。

## DeepDream：放大已有特征

这是一个前几年来自谷歌的项目，叫做DeepDream

我们想使用一张已有的图像，然后放大图像中存在的任何特征（这些特征是网络想要识别的），那么我们可以这样完成：将原始图像传入CNN的某些层来提取特征，然后将层的梯度设置为激活值本身，然后进行反向传播并且更新图像，这样就可以使得图像中的特征更为强烈，这个也相当于最大化L2范数

通过多次重复这个过程，DeepDream就可以逐步地修改图像，使其越来越像网络的“梦境”。

这是因为卷积神经网络是一种深度学习模型，可以从数据中学习到复杂的特征，例如，网络可以从一堆图片中学习到如何识别狗、猫、车辆、建筑物等等，我们使用放大特征的方法，这就好像我们让网络“梦想”起这个层所知道的所有特征，然后将这些梦想画在原始图像上

例如，如果我们选择的层是可以识别狗脸的，那么DeepDream可能就会在图像中创造出很多奇特的狗脸。这些狗脸可能会有各种各样的形状和颜色，甚至会在我们原本看不出狗脸的地方出现。这就是为什么我们说这个图像是网络的“梦境”。

所以，当我们说DeepDream生成的是神经网络的“梦境”，实际上是指这个图像反映了网络在识别和解释世界时所学习到的特征。

![EECS498_L14_48](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_48.jpg)

## 纹理合成

我们知道，计算机图形学里面有纹理合成的任务，我们想要做的是输入一些小图像块，提供一些规则纹理，然后我们想要生成一些文本，一些输出图像，这些图像可能要大得多（如下图所示），这个可以使用一些经典算法完成

![EECS498_L14_52](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_52.jpg)

实证明我们实际上可以不用神经网络就可以做出很好的纹理合成，只要我们的纹理很简单，但是我们也可以使用神经网络来实现纹理合成，也就是使用梯度反传来解决纹理合成任务（类似于特征反转）

在特征反转中，我们有一些原始输入图像，想生成一个与输入特征匹配的新图像，现在我们想使用类似的想法来生成纹理，但是我们不希望它匹配输入图像的确切像素，我们希望它能与输入图像的局部纹理特征的整体空间结构相匹配

我们要做的是使用一种叫做**格拉姆矩阵（Gram matrix）**，这是一种从CNN捕获局部纹理信息同时丢弃所有空间信息的方法

我们选择神经网络的某个层，然后通过网络运行我们的纹理图像我们的目标图像，并且提取这个特征表示，对这些特征表示计算格拉姆矩阵，这将捕捉到图像中的纹理信息，这是因为网络的每一层都会输出一个特征图，这个特征图就是这一层的特征表示。这些特征图会随着网络层次的深入而逐渐从捕捉简单特征（或者说更细粒度的纹理特征或者低级特征）转向捕捉复杂特征（或者说更抽象的纹理特征），可以选择其中的一层或多层来提取特征表示。

![EECS498_L14_56](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L14_56.jpg)

选择的特征表示通常是一个形状为(C, H, W)的三维张量，其中C是通道数量，H和W分别是特征图的高和宽。为了计算格拉姆矩阵，你首先需要将这个3D张量转换为一个2D矩阵，形状为(C, H*W)，你可以通过reshape或flatten操作来实现这一步。然后，你计算这个2D矩阵与其自身的转置的乘积，得到的就是格拉姆矩阵，其形状为(C, C)。每个元素都是相应两个通道的特征向量的内积，可以被理解为这两个特征在图像中的相关性或共现度。

如果你从特征图中抽取两个C维向量并计算它们的格拉姆矩阵，实际上你就在计算这两个向量的外积。这种方法常常被用来衡量两个向量之间的关系。

这样的话，格拉姆矩阵的元素是两个向量的内积，可以表示这两个向量之间的相关性。如果你将特征图中的每个位置看作一个独立的样本，那么这个格拉姆矩阵就可以看作这两个向量在所有样本上的协方差矩阵。这个协方差矩阵可以提供关于这两个向量分布和关系的信息。

例如，如果你正在处理图像，并且你的向量是来自卷积层的特征图，那么这个协方差矩阵就可以捕捉到图像中的纹理信息。在这种情况下，每个元素的值都表示了相应的两个特征通道在图像的空间布局中的相关性。

因此，计算特征图中两个C维向量的格拉姆矩阵可以帮助你理解这两个向量的关系，以及它们在数据中的分布和交互。这对于理解你的模型，以及设计新的模型和算法都是有用的。

## 神经风格迁移

实际上这个算法倾向于捕捉纹理和色彩，所以适合迁移印象派的风格，不适合写实派

# 总结

我们有许多的可以理解神经网络表示的方法

## 激活

最近邻方法，降维，最大激活区域，遮挡

## 有趣方法

纹理合成，神经风格迁移