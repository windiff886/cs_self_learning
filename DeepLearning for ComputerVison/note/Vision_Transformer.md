# Vision Transformer

简称ViT，实际上是Transformer在计算机视觉中的应用，或者说带有Transformer的计算机视觉方法，而Transformer是建立在注意力机制上的一种神经网络架构，其核心组件就是注意力机制，可以实现动态的关注序列中某些重要部分

注意力机制实际上是一种自适应的卷积核，而CNN是固定大小的卷积核，所以注意力机制下的计算机视觉实际上就是带有了自适应感受野的卷积网络，搜索空间更大，提高了准确度的上限，但是带来了训练成本更高的问题（要在更大范围内搜索最优解），导致现在工程落地中，很少使用ViT方案，更多地使用传统CNN方案

此外，ViT的训练需要更大的数据集，如果数据集不够大，那么ViT的性能表现反而不如CNN，这是因为ViT缺少一些CNN固有的性质，比如说平移不变性和局部参数共享，所以在数据集不够大的情况下，泛化能力不是很好

# 综述



# SENet

Squeeze-and-Excitation Networks，简称SENet，主要的创新是引入了注意力机制并且实现了通道之间关联性的学习，或者说实现了通道注意力机制，在传统的卷积神经网络（CNN）结构中，不同通道之间的特征信息是独立处理的，没有考虑到通道之间的相关性。SENet引入了一种注意力机制，使得网络可以动态地对不同通道的特征进行加权，从而更加关注重要的特征信息，抑制不重要的特征，这种特性使得网络具备更强的特征表示能力。

![SENet_1](.\assets\SENet_1.png)

SENet的基本模块称为SE block，一个模块会考虑通道之间的关系并且进行学习，这个模块不仅可以用来堆叠并且构成一个SENet，还可以任意嵌入其他的网络

## Squeeze步骤

在这一步中，SENet通过全局平均池化（global average pooling）来对每个通道的特征图进行压缩（这也是Squeeze的本意）。这个过程将特征图转换为一个单一的数值，即通道的全局特征。这样做的目的是为了摄取每个通道的全局统计信息，以便后续的注意力机制对各个通道的重要性进行评估，实现了对通道依赖关系的利用，或者说在输出部分可以利用区域以外的上下文信息。

当然，可以使用其他的复杂聚合方法来实现，全局平均池化是其中一种

## Excitation步骤

在获取了各个通道的全局特征之后，就是进行Excitation（激励）步骤了，这是一个自适应重标定的过程，可以实现对前一步中汇聚的信息的利用，在这一步中，SENet利用一个或者多个小型的多层感知机（MLP）来学习对应于每个通道的重要性权重。该MLP接收来自Squeeze步骤得到的全局特征作为输入，并输出一个通道注意力向量。这个通道注意力向量通过对每个通道进行逐元素乘法，来动态地对特征图的每个通道进行加权

## 应用

我们可以将SE模块和现代CNN架构结合，然后实现一些功能

我们使用Inception与SE结合，得到

![SENet_2](.\assets\SENet_2.png)

与ResNet结合得到

![SENet_3](.\assets\SENet_3.png)

# Non-local Neural Network

这是CVPR2018的论文，是一篇很核心的文章

当时的CNN和RNN都是一种局部的操作（Local operations），都是受到图像处理中的非局部均值方法启发，提出了非局部操作的方法，或者说是长距离依赖的想法，也就是说在计算的时候会考虑远处的信息，而且不一定是在同一个维度上的，比如说在图像上会考虑像素与像素之间的关系，在视频中会考虑不同时间中不同位置区域的关系，在语言中会考虑不同词汇之间的关系，而且这个操作可以插入到很多网络中去

在CNN或者RNN中，长距离的依赖关系，只能通过多层卷积操作堆叠带来的大感受野来进行计算，或者说CNN和RNN中的卷积与循环操作，都是一种局部关系的计算方法，需要重复多次局部计算才可以去计算长距离依赖，但是这种重复性的局部计算是效率很低的，并且会导致训练上的困难，还有信息传递困难的情况，非局部操作就可以有效解决这些问题，并且可以通过更少的层来实现很好的效果，此外，非局部操作也是注意力机制的一种实现，可以接受任意大小的输入并且可以与其他操作进行组合

![Non_local_Neural_Network_1](.\assets\Non_local_Neural_Network_1.png)

比如说在这个视频分类问题中，在时间和空间维度上进行了非局部操作，比如说这个球的位置$X_i$就是由所有位置计算得到的，其中权重高的一些显示在上图中

在此方法中，基本的模块为non-local block，

下面是non-local操作的数学定义
$$
y_i=\frac{1}{C(x)}\sum_{\forall j}f(x_i,x_j)g(x_j)
$$
其中$x$是输入的信号，可以是图像、序列、视频等等，通常是他们的特征，$y$是输出信号，形状与输入一致，$i$是输出位置的索引（可以是时间或者空间上，或者时空上），$j$是枚举所有可能位置的索引，成对函数$f$计算$i$和所有的$j$之间的关系（比如说依赖程度）并且结果为标量，一元函数$g$计算输入信号在$j$位置的一个表示，并且会使用因子$C(x)$对响应进行归一化处理；在这个non-local操作中，任何一个响应的输出，依赖于所有位置及不同位置之间依赖关系的计算，这与CNN中局部卷积操作有很大区别

此外，non-local与全连接层FC之间的区别是，前者的计算依赖于不同位置之间的关系，并且可以接受任意形状的数据输入，同时可以插入CNN/RNN的网络架构任意位置，后者的计算依赖于可学习参数，与输入数据之间的关系无关，并且只能接受固定大小的输入和放置于网络末端

那么，其中的三个函数具体有哪些呢？

- $g$：这个函数可以是最简单的线性可学习参数形式，与FC类似，公式为$g(x_j)=W_gx_j$，这种操作类似1x1卷积
- $f$：成对函数的一个天然的选择就是点积，这是一种很数学的计算相似性的方法，并且在现代深度学习中可以很容易的实现计算，在这里外卖可以定义$f(x_i,x_j)=e^{x_i^Tx_j}$，此外欧式距离也可以作为成对函数
- $C$：归一化因子定义为$C(x)=\sum_{\forall j}f(x_i,x_j)$

此外，non local block比三维卷积在计算上更经济

# CBAM: Convolutional Block Attention Module



# Transformer for Image Recognition at Scale

这是第一篇真正意义上的Vision Transformer工作，应用于图像分类，核心思想是将图像切为小块或者说patch作为序列处理，经过Transformer处理之后，模型就可以去关注某些重要部分

在这篇文章之前，Transformer主要应用在NLP领域，CV领域只有一些带有注意力机制的方法如SENet等，无法实际应用Transformer的一个问题就是没办法对所有的像素进行注意力机制的应用，否则会产生极其巨大的计算量，所以只能进行一些近似的方法，比如说只在像素的周边邻域进行注意力计算，局部多头点积自注意力模块可以完全代替卷积

在这篇文章中，作者尽可能按照原始论文中的方式去设计ViT架构，这样便于ViT模块任意嵌入和使用

首先，我们有一个图像$x\in \mathbb{R}^{H\times W\times C}$，然后将其变换为一个展开的2D patch的序列，即
$$
x_p\in \mathbb{R}^{N\times (P^2\cdot C)}
$$
其中H、W是原始图像分辨率，C是通道数，(P,P)是每个patch的分辨率，N是patch的数量，或者说patch序列的长度，需要满足公式$N=HW/P^2$

同时，这里所有层使用的隐向量长度为$D$，所有我们将图片展平，并且使用可训练的线性投影投射至D维，此投影的输出称为patch embeddings（或者称为补丁嵌入）