# 学习过程

在前面章节中，我们讨论了神经网络的静态部分：如何创建网络的连接、数据和损失函数。本节将致力于讲解神经网络的动态部分，即神经网络学习参数和搜索最优超参数的过程。  

## 学习率设置

在深度学习过程中，学习率可以说是最重要的一个超参数，学习率的设置尤为重要，决定了模型的学习速度与效果

但是，学习率不是越大越好的，如果过大，可能导致损失和梯度直接爆炸，导致网络无法训练，或者模型无法收敛到接近最近，如果过小，会导致网络学习速度很慢，需要很长时间才可以完成收敛，这几种情况才可以从下图中看到

所以我们需要找到一种非常好的学习率，使得网络既可以快速学习，也可以收敛到一个很好的状态，但是明显一个固定的学习率是无法完成这个任务的，我们需要使得学习率可以变化——先是较大的学习率，然后是更小的学习率

![EECS498_L11_15](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L11_15.jpg?raw=true)

实际上也有很多不同的学习率的设置方法

### 步进衰减

步进式递减的方式，就是在某些节点上降低学习率，比如说ResNet这种，就是每三十轮训练就会学习率变为原来的十分之一（如图）

![EECS498_L11_16](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L11_16.jpg?raw=true)

可以看到，实际上每次步进后的第20-30个epoch，网络就会再次进入一个稳定状态，然后再一次进行学习率衰减，就可以重新进入一个相对快速的学习状态

但是，这种方式引入了很多的新超参数，但是实际上很难去测试那么多的参数哪一个更好用，所以还是有一些缺点的

### 余弦式衰减

为了克服步进衰减的一些缺点，近年来余弦式衰减开始流行起来，使用一种余弦式函数来完成这个学习率衰减的过程

![EECS498_L11_17](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L11_17.jpg?raw=true)

这个方式的好处就是，只有两个参数需要设置（初始学习率$\alpha_0$，训练周期T），更加方便

### 线性衰减

这种最简单，学习率进行线性下降

![EECS498_L11_18](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L11_18.jpg?raw=true)

### 平方根倒数衰减

这是2017年提出的一种方案，但是存在的缺陷是，模型实际上在最初的高学习率上花费的时间少，在后面的低学习率上花费较多时间，而其他的衰减方案往往在初始的高学习率上花费更多时间，容易导致最开始的时候模型收敛缓慢

![EECS498_L11_19](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L11_19.jpg?raw=true)

### 总结

目前并没有很好的研究（视频中如此）来对比这些不同的学习率衰减方案，所以并没有办法比较他们之间的优劣，但是深度学习的不同领域会对不同的方案有所偏好

计算机视觉领域经常性使用余弦式衰减，大规模语言模型经常使用线性衰减

## 梯度检查

理论上将进行梯度检查很简单，就是简单地把解析梯度和数值计算梯度进行比较。然而从实际操作层面上来说，这个过程更加复杂且容易出错。下面是一些提示、技巧和需要仔细注意的事情：

**使用中心化公式。**在使用有限差值近似来计算数值梯度的时候，常见的公式是：

![displaystyle frac{df\(x\)}{dx}=frac{f\(x+h\)-f\(x\)}{h}\(bad, do not use\)](http://zhihu.com/equation?tex=%5Cdisplaystyle+%5Cfrac%7Bdf%28x%29%7D%7Bdx%7D%3D%5Cfrac%7Bf%28x%2Bh%29-f%28x%29%7D%7Bh%7D%28bad%2C%5C+do%5C+not%5C+use%29] )

其中![h][12]是一个很小的数字，在实践中近似为1e-5。在实践中证明，使用_中心化_公式效果更好：  

![displaystyle frac{df\(x\)}{dx}=frac{f\(x+h\)-f\(x-h\)}{2h}\(use instead\)](http://zhihu.com/equation?tex=%5Cdisplaystyle+%5Cfrac%7Bdf%28x%29%7D%7Bdx%7D%3D%5Cfrac%7Bf%28x%2Bh%29-f%28x-h%29%7D%7B2h%7D%28use%5C+instead%29)

该公式在检查梯度的每个维度的时候，会要求计算两次损失函数（所以计算资源的耗费也是两倍），但是梯度的近似值会准确很多。要理解这一点，对$f(x+h)$和$f(x-h)$使用泰勒展开，可以看到第一个公式的误差近似![O\(h\)][16]，第二个公式的误差近似![O\(h^2\)][17]（是个二阶近似）。_**（译者注：泰勒展开相关内容可阅读《高等数学》第十二章第四节：函数展开成幂级数。）**_

**使用相对误差来比较**。比较数值梯度![f'_n][18]和解析梯度![f'_a][19]的细节有哪些？如何得知此两者不匹配？你可能会倾向于监测它们的差的绝对值![|f'_a-f'_n|][20]或者差的平方值，然后定义该值如果超过某个规定阈值，就判断梯度实现失败。然而该思路是有问题的。想想，假设这个差值是1e-4，如果两个梯度值在1.0左右，这个差值看起来就很合适，可以认为两个梯度是匹配的。然而如果梯度值是1e-5或者更低，那么1e-4就是非常大的差距，梯度实现肯定就是失败的了。因此，使用_相对误差_总是更合适一些：  

![displaystyle frac{|f'_a-f'_n|}{max\(|f'_a|,|f'_n|\)}][21]  

上式考虑了差值占两个梯度绝对值的比例。注意通常相对误差公式只包含两个式子中的一个（任意一个均可），但是我更倾向取两个式子的最大值或者取两个式子的和。这样做是为了防止在其中一个式子为0时，公式分母为0（这种情况，在ReLU中是经常发生的）。然而，还必须注意两个式子都为零且通过梯度检查的情况。在实践中：  

* 相对误差&gt;1e-2：通常就意味着梯度可能出错。
* 1e-2&gt;相对误差&gt;1e-4：要对这个值感到不舒服才行。
* 1e-4&gt;相对误差：这个值的相对误差对于有不可导点的目标函数是OK的。但如果目标函数中没有kink（使用tanh和softmax），那么相对误差值还是太高。
* 1e-7或者更小：好结果，可以高兴一把了。

要知道的是网络的深度越深，相对误差就越高。所以如果你是在对一个10层网络的输入数据做梯度检查，那么1e-2的相对误差值可能就OK了，因为误差一直在累积。相反，如果一个可微函数的相对误差值是1e-2，那么通常说明梯度实现不正确。  

  

**使用双精度。**一个常见的错误是使用单精度浮点数来进行梯度检查。这样会导致即使梯度实现正确，相对误差值也会很高（比如1e-2）。在我的经验而言，出现过使用单精度浮点数时相对误差为1e-2，换成双精度浮点数时就降低为1e-8的情况。

**保持在浮点数的有效范围。**建议通读《[What Every Computer Scientist Should Konw About Floating-Point Artthmetic__][22]》一文，该文将阐明你可能犯的错误，促使你写下更加细心的代码。例如，在神经网络中，在一个批量的数据上对损失函数进行归一化是很常见的。但是，如果每个数据点的梯度很小，然后又用数据点的数量去除，就使得数值更小，这反过来会导致更多的数值问题。这就是我为什么总是会把原始的解析梯度和数值梯度数据打印出来，确保用来比较的数字的值不是过小（通常绝对值小于1e-10就绝对让人担心）。如果确实过小，可以使用一个常数暂时将损失函数的数值范围扩展到一个更"好"的范围，在这个范围中浮点数变得更加致密。比较理想的是1.0的数量级上，即当浮点数指数为0时。

  

**目标函数的不可导点（kinks）**。在进行梯度检查时，一个导致不准确的原因是不可导点问题。不可导点是指目标函数不可导的部分，由ReLU（![max\(0,x\)][23]）等函数，或SVM损失，Maxout神经元等引入。考虑当![x=-1e6][24]的时，对ReLU函数进行梯度检查。因为![x&lt;0][25]，所以解析梯度在该点的梯度为0。然而，在这里数值梯度会突然计算出一个非零的梯度值，因为![f\(x+h\)][14]可能越过了不可导点(例如：如果![h&gt;1e-6][26])，导致了一个非零的结果。你可能会认为这是一个极端的案例，但实际上这种情况很常见。例如，一个用CIFAR-10训练的SVM中，因为有50,000个样本，且根据目标函数每个样本产生9个式子，所以包含有450,000个![max\(0,x\)][23]式子。而一个用SVM进行分类的神经网络因为采用了ReLU，还会有更多的不可导点。

  

注意，在计算损失的过程中是可以知道不可导点有没有被越过的。在具有![max\(x,y\)][27]形式的函数中持续跟踪所有"赢家"的身份，就可以实现这一点。其实就是看在前向传播时，到底x和y谁更大。如果在计算![f\(x+h\)][14]和![f\(x-h\)][15]的时候，至少有一个"赢家"的身份变了，那就说明不可导点被越过了，数值梯度会不准确。

  

**使用少量数据点。**解决上面的不可导点问题的一个办法是使用更少的数据点。因为含有不可导点的损失函数(例如：因为使用了ReLU或者边缘损失等函数)的数据点越少，不可导点就越少，所以在计算有限差值近似时越过不可导点的几率就越小。还有，如果你的梯度检查对2-3个数据点都有效，那么基本上对整个批量数据进行梯度检查也是没问题的。所以使用很少量的数据点，能让梯度检查更迅速高效。

**谨慎设置步长h。**在实践中h并不是越小越好，因为当![h][12]特别小的时候，就可能就会遇到数值精度问题。有时候如果梯度检查无法进行，可以试试将![h][12]调到1e-4或者1e-6，然后突然梯度检查可能就恢复正常。这篇[维基百科文章__][28]中有一个图表，其x轴为![h][12]值，y轴为数值梯度误差。

**在操作的特性模式中梯度检查。**有一点必须要认识到：梯度检查是在参数空间中的一个特定（往往还是随机的）的单独点进行的。即使是在该点上梯度检查成功了，也不能马上确保全局上梯度的实现都是正确的。还有，一个随机的初始化可能不是参数空间最优代表性的点，这可能导致进入某种病态的情况，即梯度看起来是正确实现了，实际上并没有。例如，SVM使用小数值权重初始化，就会把一些接近于0的得分分配给所有的数据点，而梯度将会在所有的数据点上展现出某种模式。一个不正确实现的梯度也许依然能够产生出这种模式，但是不能泛化到更具代表性的操作模式，比如在一些的得分比另一些得分更大的情况下就不行。因此为了安全起见，最好让网络学习（"预热"）一小段时间，等到损失函数开始下降的之后再进行梯度检查。在第一次迭代就进行梯度检查的危险就在于，此时可能正处在不正常的边界情况，从而掩盖了梯度没有正确实现的事实。

  

**不要让正则化吞没数据。**通常损失函数是数据损失和正则化损失的和（例如L2对权重的惩罚）。需要注意的危险是正则化损失可能吞没掉数据损失，在这种情况下梯度主要来源于正则化部分（正则化部分的梯度表达式通常简单很多）。这样就会掩盖掉数据损失梯度的不正确实现。因此，推荐先关掉正则化对数据损失做单独检查，然后对正则化做单独检查。对于正则化的单独检查可以是修改代码，去掉其中数据损失的部分，也可以提高正则化强度，确认其效果在梯度检查中是无法忽略的，这样不正确的实现就会被观察到了。

**记得关闭随机失活（dropout）和数据扩张（augmentation）**。在进行梯度检查时，记得关闭网络中任何不确定的效果的操作，比如随机失活，随机数据扩展等。不然它们会在计算数值梯度的时候导致巨大误差。关闭这些操作不好的一点是无法对它们进行梯度检查（例如随机失活的反向传播实现可能有错误）。因此，一个更好的解决方案就是在计算![f\(x+h\)][14]和![f\(x-h\)][15]前强制增加一个特定的随机种子，在计算解析梯度时也同样如此。  

**检查少量的维度。**在实际中，梯度可以有上百万的参数，在这种情况下只能检查其中一些维度然后假设其他维度是正确的。**注意****：**确认在所有不同的参数中都抽取一部分来梯度检查。在某些应用中，为了方便，人们将所有的参数放到一个巨大的参数向量中。在这种情况下，例如偏置就可能只占用整个向量中的很小一部分，所以不要随机地从向量中取维度，一定要把这种情况考虑到，确保所有参数都收到了正确的梯度。  

  

## 学习之前：合理性检查的提示与技巧

在进行费时费力的最优化之前，最好进行一些合理性检查：

* **寻找特定情况的正确损失值。**在使用小参数进行初始化时，确保得到的损失值与期望一致。最好先单独检查数据损失（让正则化强度为0）。例如，对于一个跑CIFAR-10的Softmax分类器，一般期望它的初始损失值是2.302，这是因为初始时预计每个类别的概率是0.1（因为有10个类别），然后Softmax损失值正确分类的负对数概率：-ln(0.1)=2.302。对于Weston Watkins SVM，假设所有的边界都被越过（因为所有的分值都近似为零），所以损失值是9（因为对于每个错误分类，边界值是1）。如果没看到这些损失值，那么初始化中就可能有问题。
* 第二个合理性检查：提高正则化强度时导致损失值变大。
* **对小数据子集过拟合。**最后也是最重要的一步，在整个数据集进行训练之前，尝试在一个很小的数据集上进行训练（比如20个数据），然后确保能到达0的损失值。进行这个实验的时候，最好让正则化强度为0，不然它会阻止得到0的损失。除非能通过这一个正常性检查，不然进行整个数据集训练是没有意义的。但是注意，能对小数据集进行过拟合并不代表万事大吉，依然有可能存在不正确的实现。比如，因为某些错误，数据点的特征是随机的，这样算法也可能对小数据进行过拟合，但是在整个数据集上跑算法的时候，就没有任何泛化能力。

  

## 检查整个学习过程

在训练神经网络的时候，应该跟踪多个重要数值。这些数值输出的图表是观察训练进程的一扇窗口，是直观理解不同的超参数设置效果的工具，从而知道如何修改超参数以获得更高效的学习过程。

  

在下面的图表中，x轴通常都是表示**_周期（epochs）_**单位，该单位衡量了在训练中每个样本数据都被观察过次数的期望（一个周期意味着每个样本数据都被观察过了一次）。相较于迭代次数（iterations），一般更倾向跟踪周期，这是因为迭代次数与数据的批尺寸（batchsize）有关，而批尺寸的设置又可以是任意的。

## 超参数选择

在实际训练模型的过程中，我们会面临很多超参数选择的问题，我们应该如何设置一个合适的超参数呢

### 网格搜索

我们选择一些关心的超参数集，对其中每一个超参数，我们选择一些想要评估的数值集（对数线性的方式），然后测试不同的组合，比如说权重衰减和学习率从10的-1次方到-4次方，然后进行组合和尝试

![EECS498_L11_23](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L11_23.jpg)

但是这需要非常多次的尝试，需要非常多的算力，而且要调整的次数是超参数数量的指数倍，故这不是一种很好的方法

### 随机搜索

我们还是找到那个对数线性排列的范围，然后在该范围的每种参数类型里面选一个随机值来进行训练

随机搜索的效果会比网格搜索更好，这是在2012年的一篇论文中提到的，其中的想法是，如果你有很多的超参数需要调整，但是你不知道这些超参数哪一个对模型性能的影响更大（或者说哪些超参数对模型的性能影响很小）

如果我们考虑超参数对模型影响的边缘分布的话，可能会出现下面的情况

![EECS498_L11_25](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L11_25.jpg)

某些对模型性能无关紧要的超参数与某些有影响的超参数一起网格搜索的话，会产生无用的计算，得到的信息中很多事无用信息（或者说我们无法得到重要类型超参数的更多有效样本），但是随机搜索的话，可以获得更多信息，则可以进行对比

下面是讲师使用大量GPU对不同网络模型进行多次试验得到分布图

![EECS498_L11_26](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/EECS498_L11_26.jpg)

### 无大量GPU的方法

#### Step1：检查初始损失

假定已经实现了模型，那么第一步就是通过损失函数的结构来分析计算你在随机初始化的时候期望什么样的初始损失，比如说交叉熵损失，你知道它应该减去类数的对数

然后关闭权重衰减，并在初始化时检查这种损失，它只要一次迭代，它非常便宜，非常快

如果损失是错误的，那就需要去修复

#### Step2：进行过拟合

下一步是尝试过拟合你的训练数据中一个非常小批量的样本，尝试过拟合到百分百（可能需要关闭正则化，或者加上其他的方法），使得你正在处理的模型可以在非常小的训练集上达到百分百准确率（或者说找到一组超参数使得你可以完成），这些操作可以保证你的优化循环中没有任何错误，因为如果你不能拟合一小批数据，那么自然无法完成对大训练集的拟合（这个阶段会发现很多错误）

#### Step3：找到一个可以让损失快速下降的学习率

如果可以做到过拟合，那就使用这个架构，现在使用所有的训练数据，你的目标是找到一个学习率，可以使得损失在你的整个训练集上开始快速下降

这个时候你只需要改变学习率就可以。你的目标是损失在前一百次左右的训练迭代中显着下降

## 损失函数

训练期间第一个要跟踪的数值就是损失值，它在前向传播时对每个独立的批数据进行计算。下图展示的是随着损失值随时间的变化，尤其是曲线形状会给出关于学习率设置的情况：

————————————————————————————————————————

![][29]**左图**展示了不同的学习率的效果。过低的学习率导致算法的改善是线性的。高一些的学习率会看起来呈几何指数下降，更高的学习率会让损失值很快下降，但是接着就停在一个不好的损失值上（绿线）。这是因为最优化的"能量"太大，参数在混沌中随机震荡，不能最优化到一个很好的点上。**右图**显示了一个典型的随时间变化的损失函数值，在CIFAR-10数据集上面训练了一个小的网络，这个损失函数值曲线看起来比较合理（虽然可能学习率有点小，但是很难说），而且指出了批数据的数量可能有点太小（因为损失值的噪音很大）。

————————————————————————————————————————

损失值的震荡程度和批尺寸（batch size）有关，当批尺寸为1，震荡会相对较大。当批尺寸就是整个数据集时震荡就会最小，因为每个梯度更新都是单调地优化损失函数（除非学习率设置得过高）。

有的研究者喜欢用对数域对损失函数值作图。因为学习过程一般都是采用指数型的形状，图表就会看起来更像是能够直观理解的直线，而不是呈曲棍球一样的曲线状。还有，如果多个交叉验证模型在一个图上同时输出图像，它们之间的差异就会比较明显。

有时候损失函数看起来很有意思：[lossfunctions.tumblr.com__][30]。

### 训练集和验证集准确率

在训练分类器的时候，需要跟踪的第二重要的数值是验证集和训练集的准确率。这个图表能够展现知道模型过拟合的程度：  

————————————————————————————————————————

![][31]在训练集准确率和验证集准确率中间的空隙指明了模型过拟合的程度。在图中，蓝色的验证集曲线显示相较于训练集，验证集的准确率低了很多，这就说明模型有很强的过拟合。遇到这种情况，就应该增大正则化强度（更强的L2权重惩罚，更多的随机失活等）或收集更多的数据。另一种可能就是验证集曲线和训练集曲线如影随形，这种情况说明你的模型容量还不够大：应该通过增加参数数量让模型容量更大些。

————————————————————————————————————————

### 权重更新比例

最后一个应该跟踪的量是权重中更新值的数量和全部值的数量之间的比例。注意：是_更新的_，而不是原始梯度（比如，在普通sgd中就是梯度乘以学习率）。需要对每个参数集的更新比例进行单独的计算和跟踪。一个经验性的结论是这个比例应该在1e-3左右。如果更低，说明学习率可能太小，如果更高，说明学习率可能太高。下面是具体例子：
    
    
```py
    # 假设参数向量为W，其梯度向量为dW
    param_scale = np.linalg.norm(W.ravel())
    update = -learning_rate*dW # 简单SGD更新
    update_scale = np.linalg.norm(update.ravel())
    W += update # 实际更新
    print update_scale / param_scale # 要得到1e-3左右

```

相较于跟踪最大和最小值，有研究者更喜欢计算和跟踪梯度的范式及其更新。这些矩阵通常是相关的，也能得到近似的结果。

  

### 每层的激活数据及梯度分布

一个不正确的初始化可能让学习过程变慢，甚至彻底停止。还好，这个问题可以比较简单地诊断出来。其中一个方法是输出网络中所有层的激活数据和梯度分布的柱状图。直观地说，就是如果看到任何奇怪的分布情况，那都不是好兆头。比如，对于使用tanh的神经元，我们应该看到激活数据的值在整个[-1,1]区间中都有分布。如果看到神经元的输出全部是0，或者全都饱和了往-1和1上跑，那肯定就是有问题了。

## 第一层可视化

最后，如果数据是图像像素数据，那么把第一层特征可视化会有帮助：

————————————————————————————————————————

![][32]将神经网络第一层的权重可视化的例子。**左图**中的特征充满了噪音，这暗示了网络可能出现了问题：网络没有收敛，学习率设置不恰当，正则化惩罚的权重过低。**右图**的特征不错，平滑，干净而且种类繁多，说明训练过程进行良好。

# 代码实现：人脸表情识别

前面是一系列的理论部分，接下来我们介绍如何使用代码完成这些操作，构建一个简单但是完整的项目，并且使用工业级项目的流程

![YSAI_ImageClassification_L3-1_4](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/YSAI_ImageClassification_L3-1_4.png)

我们从网络上爬取一些有人脸表情标签的数据，然后将其中嘴部区域单独提取出来并且做成统一大小，然后以此作为训练集和验证集进行训练

## 数据准备

有三种方式，数据集，外包平台或者网络爬虫

数据集可以直接使用公开的数据集

外包平台适用于大公司大团队定制数据集

网络爬虫可以自己爬取，成本低，种类丰富，速度快

### 人脸表情识别开源数据集

其中除去针对标签的数据集，针对人脸属性的数据集主要是Celeba等

![YSAI_ImageClassification_L3-2_3](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/YSAI_ImageClassification_L3-2_3.png?raw)

### 网络爬虫

我们可以通过这个爬虫工具，在百度上搜索带有某个关键词的图片，并且批量保存和规范化命名

![YSAI_ImageClassification_L3-2_4](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/YSAI_ImageClassification_L3-2_4.png)

## 数据预处理

在准备好了爬虫搜集的数据之后，我们需要对其进行处理，剔除一些不好的数据，这样子在训练的时候效果更好，具体的操作如下

![YSAI_ImageClassification_L3-2_17](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/YSAI_ImageClassification_L3-2_17.png)

并且我们需要使用经典算法，进行人脸检测，并且把嘴部区域单独摘出来

![YSAI_ImageClassification_L3-2_25](https://raw.githubusercontent.com/Michael-Jetson/Images/main/UpGit_Auto_UpLoad/YSAI_ImageClassification_L3-2_25.png)

## 读取数据与增强

图像分类任务可以直接使用`torchvision`包来读取数据，只要我们的文件夹目录格式正确，就可以一键完成读取

一般来说，我们会把所有的训练数据放到`data`文件夹下，然后data文件夹分为训练集`train`和验证集`val`，每个集合都包括多个类的子文件夹，这些会被`torchvision`自动转成标签，减少工作量

```python
import torchvision.dataset as dataset
import torchvision.transforms as transforms 
data_dir='./data'#数据集总目录
train_dataset=ds.ImageFolder(os.path.join(data_dir,'train'),data_transforms)#读取数据，转为Dataset实例
dataloader=data.DataLoader(data)#转化为DataLoader实例，便于下一步的训练
```

这个代码的作用就是，从数据目录里面读取数据的信息，并且进行一些操作（比如说裁剪和翻转等），然后生成DataLoader实例

### Dataset类：读取并处理数据

Dataset类在PyTorch中可以说是最重要的部分了，如果我们搞清楚了，就可以创建适应任意模型的数据集接口，去读取数据集中的每个数据进行训练

所谓数据集，无非就是一组{x,y}的集合，x是数据，y是标签，你只需要在这个类里说明“有一组{x,y}的集合”就可以了。

对于图像分类任务，图像+分类

对于目标检测任务，图像+bbox、分类

对于超分辨率任务，低分辨率图像+超分辨率图像

对于文本分类任务，文本+分类

你只需在代码中定义好这个项目的x和y是什么，然后在运行的时候计算机就会自动读取并且处理你的数据，幸运的是，PyTorch官方给我们提供了一个基类Dataset类，我们可以在这个的基础上轻松实现这些操作

我们看一下Dataset的官方代码，其中`__getitem__`和`__len__`是子类必须继承的方法，也就是我们在自定义数据集代码的时候，要继承并且重写，`__getitem__`就是获取特定位置的{x,y}，`__len__`就是获取数据集的大小（或者说数据的长度），这样子我们就可以读取到数据集中的所有数据了

```python
class Dataset(object):
    """An abstract class representing a Dataset.
    All other datasets should subclass it. All subclasses should override
    ``__len__``, that provides the size of the dataset, and ``__getitem__``,
    supporting integer indexing in range from 0 to len(self) exclusive.
    """
 
    def __getitem__(self, index):
        raise NotImplementedError
 
    def __len__(self):
        raise NotImplementedError
 
    def __add__(self, other):
        return ConcatDataset([self, other])
```

假设我们要进行一个二分类任务，要识别一元和一百元的纸币，在`data`目录下有名为1和100的文件夹，其中存放一些对应的照片（只考虑纯照片并且格式统一的情况），我们给出一个示例，展示如何具体的去构建数据集代码

首先是导包，我们需要导入一些有利于我们构建数据集代码的函数

```python
import os#用于路径处理
from PIL import Image#用于加载图片
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
import torchvision.transforms as transforms#用于确定图像处理方式
```

然后我们去具体的构造一个类，来处理路径下的所有文件，一般来说，确定数据的标签有两种方法，一种是分文件夹存放，比如说百元大钞和一元钞票的图像，分别存放在两个文件夹中，那么我们可以以文件夹作为标签并且作一个映射，一般是映射到不同的数字（表示不同类别）

```python
class RMBDataset(Dataset):
    def __init__(self, data_dir, transform=None):
        """
        rmb面额分类任务的Dataset
        :param data_dir: str, 数据集所在路径
        :param transform: torch.transform，图像数据预处理
        """
        self.label_name = {"1": 0, "100": 1}#构建映射
        self.data_info = self.get_img_info(data_dir)#这个方法用于遍历给定目录下的所有图像文件，收集它们的路径和标签
        self.transform = transform#图像预处理的方法
 
    def __getitem__(self, index):
        path_img, label = self.data_info[index]
        img = Image.open(path_img).convert('RGB')
        if self.transform is not None:
            img = self.transform(img)
        return img, label
 
    def __len__(self):
        return len(self.data_info)
 
    def get_img_info(self, data_dir):
        # data_dir是数据集根目录，下面有一系列的类别文件夹
        data_info = list()# 存放数据的列表
        for file_dir in os.lisdir(data_dir):
            # 先遍历类别，后遍历文件，这里file_dir是类别名也是子文件夹名
            for filename in os.listdir(os.path.join(data_dir,file_dir)):
                #这里filename就是图片全名了，比如说100.png
                path_img = os.path.join(data_dir, file_dir, filename)
                label = self.label_name[sub_dir]
                data_info.append((path_img, int(label)))
    return data_info
```

这个数据集类，就是通过图像的路径和标签，然后加载图像数据（或者其他类型的数据）和标签用于下一步的训练

不过注意一下，我们只是提前加载了索引关系，并没有直接加载图片内容，这就好比说我们记录了一个地址簿，我们可以通过地址去找到具体的人，这里的自定义数据集类就好比那个地址簿，提前记录了所有的数据对应关系，当需要使用的时候就去加载

至于为什么不能提前加载呢，这是因为数据想要使用就要先从磁盘读取放到内存中，但是如果我们一次性加载了所有的数据，那么内存会爆掉，目前的数据集大一点的就以GB计算，一般情况下内存无法直接加载所有的数据集，只能先定义索引便于寻找，然后到具体用到某些数据的时候再去加载

我们看一下是如何定义这种关系的，首先是在`get_img_info`函数，顾名思义就是得到图像信息的函数，是用来构建数据列表的，它返回数据列表data_info，data_info中的元素由元组(图像路径，图像标签)构成，或者可以这样理解，我们记录了所有的数据集的位置和标签（信息保存在列表中），然后在需要具体要使用的时候，就根据位置去读取图片并且进行一些处理，然后送进深度学习模型中，而具体读取的步骤就是通过方法`__getitem___`实现的，读取图片数据，然后进行预处理，返回数据和标签

```python
    def get_img_info(self, data_dir):
        # data_dir是数据集根目录，下面有一系列的类别文件夹
        data_info = list()# 存放数据的列表
        for file_dir in os.lisdir(data_dir):
            # 先遍历类别，后遍历文件，这里file_dir是类别名也是子文件夹名
            for filename in os.listdir(os.path.join(data_dir,file_dir)):
                #这里filename就是图片全名了，比如说100.png
                path_img = os.path.join(data_dir, file_dir, filename)
                label = self.label_name[sub_dir]
                data_info.append((path_img, int(label)))
    return data_info
```

然后我们定义了这个数据集类就可以在主函数中使用了，一般来说会对训练集图像进行一些预处理，比如说规范大小、随机裁剪，然后将其从0-255的像素转化为0-1的张量，最后进行归一化，归一化的参数是给定的，这个参数是大量图片统计而来的，当然也可以自行修改（但是不建议）

```python
if __name__ == '__main__':
    norm_mean = [0.485, 0.456, 0.406]
    norm_std = [0.229, 0.224, 0.225]
    train_transform = transforms.Compose([
        transforms.Resize((32, 32)),
        transforms.RandomCrop(32, padding=4),
        transforms.ToTensor(),
        transforms.Normalize(norm_mean, norm_std),
    ])
    train_data = RMBDataset("./data/train", train_transform)
    train_loader = DataLoader(dataset=train_data, batch_size=4, shuffle=True)
```

我们在主函数中直接实例化一个我们自定义的人民币数据集对象，并且传入数据集的根目录和预处理的方法，然后构建`DataLoader`这个东西，这个东西就是将数据送入网络的关键

同时注意一下，一般来说是训练集和验证集分别设置Dataset和DataLoader的

### DataLoader：加载数据

实际上，我们读取和处理数据只是一步，还有一步就是真正的去加载数据并且送入网络中训练，这种时候就需要使用`DataLoader`对象了，这一步我们不需要自己定义怎么加载了，直接使用即可

```
DataLoader(dataset, batch_size=1, num_workers=4, shuffle=False)
```

- dataset：需要载入的数据集
- batch_size：批量大小，也就是迭代器一次送多少个样本到网络中去训练（一般为了充分利用GPU并行计算的性能，我们会一次送入很多样本去训练）
- num_workers：使用多少个子进程来加载数据，0表示只在主进程中加载数据。Pytorch会根据此参数来判断是创建单进程SingleProcessDataLoaderIter类对象，还是创建多进程MultiProcessingDataLoaderIter类对象
- shuffle：是否在每个epoch训练前打乱数据集中的样本顺序

`DataLoader`的角色，我们可以理解为是一个勤勤恳恳每次都拿出同样数量的数据样本送到网络中的工人，我们提供了一份地址簿（`Dataset`类提供的），存放着数据样本的地址和标签，然后这个工人就会勤勤恳恳的按照这个地址过去把一堆数据拿到内存中（调用的是`Dataset`类的`__getitem__`方法），然后放入网络进行训练

## 网络模型

实际上，我们可以使用现成的模型，也可以自定义模型，而在`torchvision.models`中就有很多经典模型，包括AlexNet、ResNet、ViT等等，我们可以直接加载这些模型，也可以使用预训练好的模型直接操作，在这里我们选择使用直接调用模型

## 可视化：tensorboardX

这是一个TensorFlow中的可视化工具，可以记录数据并且可视化出来，很适合深度学习

[1]: https://pic4.zhimg.com/4a97d93d652f45ededf2ebab9a13f22b_m.jpeg
[2]: https://zhuanlan.zhihu.com/intelligentunit
[3]: https://zhuanlan.zhihu.com/write
[7]: http://link.zhihu.com/?target=http%3A//cs231n.github.io/neural-networks-3/
[8]: http://link.zhihu.com/?target=http%3A//cs.stanford.edu/people/karpathy/
[9]: https://www.zhihu.com/people/kun-kun-97-81
[10]: https://www.zhihu.com/people/hmonkey
[12]: http://zhihu.com/equation?tex=h
[16]: http://zhihu.com/equation?tex=O%28h%29
[17]: http://zhihu.com/equation?tex=O%28h%5E2%29
[18]: http://zhihu.com/equation?tex=f%27_n
[19]: http://zhihu.com/equation?tex=f%27_a
[20]: http://zhihu.com/equation?tex=%7Cf%27_a-f%27_n%7C
[21]: http://zhihu.com/equation?tex=%5Cdisplaystyle+%5Cfrac%7B%7Cf%27_a-f%27_n%7C%7D%7Bmax%28%7Cf%27_a%7C%2C%7Cf%27_n%7C%29%7D
[22]: http://link.zhihu.com/?target=http%3A//docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html
[23]: http://zhihu.com/equation?tex=max%280%2Cx%29
[24]: http://zhihu.com/equation?tex=x%3D-1e6
[25]: http://zhihu.com/equation?tex=x%3C0
[26]: http://zhihu.com/equation?tex=h%3E1e-6
[27]: http://zhihu.com/equation?tex=max%28x%2Cy%29
[28]: http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Numerical_differentiation
[29]: http://pic2.zhimg.com/753f398b46cc28c1916d6703cf2080f5_b.png
[30]: http://link.zhihu.com/?target=http%3A//lossfunctions.tumblr.com
[31]: http://pic3.zhimg.com/05a6960a01c0204ced8d875ac3d91fba_b.jpg
[32]: http://pic3.zhimg.com/96573094f9d7f4b3b188069726840a2e_b.png
[33]: https://www.zhihu.com/people/ksma
[34]: https://www.zhihu.com/people/nan-tian-qi-6
